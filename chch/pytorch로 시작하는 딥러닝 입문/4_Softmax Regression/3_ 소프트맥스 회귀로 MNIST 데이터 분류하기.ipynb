{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#  소프트맥스 회귀로 MNIST 데이터 분류하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 총 60,000개의 훈련 데이터와 레이블, 총 10,000개의 테스트 데이터와 레이블로 구성\r\n",
    "* 레이블은 0부터 9까지 총 10개\r\n",
    "* 28 픽셀 × 28 픽셀 = 784 픽셀이므로, 각 이미지를 총 784의 원소를 가진 벡터\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''\r\n",
    "for X, Y in data_loader:\r\n",
    "    # 입력 이미지를 [batch_size × 784]의 크기로 reshape\r\n",
    "    # 레이블은 원-핫 인코딩\r\n",
    "  X = X.view(-1, 28*28)\r\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 토치비전(torchvision) 소개하기\r\n",
    "* torchvision은 유명한 데이터셋들, 이미 구현되어져 있는 유명한 모델들, 일반적인 이미지 전처리 도구들을 포함하고 있는 패키지가 있다\r\n",
    "* 자연어 처리를 위해서는 토치텍스트(torchtext)라는 패키지가 있다"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 분류기 구현을 위한 사전 설정"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import torchvision.datasets as dsets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import torch.nn as nn\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import random\r\n",
    "\r\n",
    "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\r\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\r\n",
    "print(\"다음 기기로 학습합니다:\", device)\r\n",
    "\r\n",
    "\r\n",
    "# 랜덤 시드 고정\r\n",
    "# for reproducibility\r\n",
    "random.seed(777)\r\n",
    "torch.manual_seed(777)\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(777)\r\n",
    "\r\n",
    "\r\n",
    "# hyperparameters\r\n",
    "training_epochs = 15\r\n",
    "batch_size = 100"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "다음 기기로 학습합니다: cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. MNIST 분류기 구현하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MNIST dataset\r\n",
    "# torchvision.datasets.dsets.MNIST\r\n",
    "mnist_train = dsets.MNIST(root='A:/chchdata/data/MNIST_data/', #MNIST 데이터를 다운로드 받을 경로\r\n",
    "                          train=True, # 훈련 데이터를 받음, False면 테스트 데이터를 받음\r\n",
    "                          transform=transforms.ToTensor(),# 파이토치 텐서로 변환\r\n",
    "                          download=True) #해당 경로에 MNIST 데이터가 없다면 다운로드 받겠다는 의미\r\n",
    "\r\n",
    "mnist_test = dsets.MNIST(root='A:/chchdata/data/MNIST_data/',\r\n",
    "                         train=False,\r\n",
    "                         transform=transforms.ToTensor(),\r\n",
    "                         download=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to A:/chchdata/data/MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "9913344it [00:18, 528822.83it/s]                             \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting A:/chchdata/data/MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to A:/chchdata/data/MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to A:/chchdata/data/MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "29696it [00:00, 169078.05it/s]                          \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting A:/chchdata/data/MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to A:/chchdata/data/MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to A:/chchdata/data/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1649664it [00:41, 39458.93it/s]                             \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting A:/chchdata/data/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to A:/chchdata/data/MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to A:/chchdata/data/MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "5120it [00:00, ?it/s]                   "
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting A:/chchdata/data/MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to A:/chchdata/data/MNIST_data/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "C:\\Users\\sswwd\\anaconda3\\envs\\chch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# dataset loader\r\n",
    "data_loader = DataLoader(dataset=mnist_train,\r\n",
    "                                          batch_size=batch_size, # 배치 크기는 100\r\n",
    "                                          shuffle=True,\r\n",
    "                                          drop_last=True) #drop_last는 마지막 배치를 버릴 것인지를 의미"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-48ed542de6da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# dataset loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m data_loader = DataLoader(dataset=mnist_train,\n\u001b[1;32m----> 3\u001b[1;33m                                           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# 배치 크기는 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m                                           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                           drop_last=True) #drop_last는 마지막 배치를 버릴 것인지를 의미\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "drop_last를 하는 이유를 이해하기 위해서 1,000개의 데이터가 있다고 했을 때, 배치 크기가 128이라고 해봅시다. 1,000을 128로 나누면 총 7개가 나오고 나머지로 104개가 남습니다. 이때 104개를 마지막 배치로 한다고 하였을 때 128개를 충족하지 못하였으므로 104개를 그냥 버릴 수도 있습니다. 이때 마지막 배치를 버리려면 drop_last=True를 해주면 됩니다. 이는 **다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대 평가되는 현상을 막아줍니다.**"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "a64de8b745ab094eb3381810b1d090f0053b4977cc21c07d5a367fb401258f96"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}