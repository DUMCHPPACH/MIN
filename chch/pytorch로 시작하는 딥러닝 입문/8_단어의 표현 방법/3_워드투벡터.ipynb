{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 분산 표현(Distributed Representation)\r\n",
    "* 분산 표현(distributed representation) 방법은 기본적으로 분포 가설(distributional hypothesis)이라는 가정 하에 만들어진 표현 방법\r\n",
    "*  '비슷한 위치에서 등장하는 단어들은 비슷한 의미를 가진다'라는 가정\r\n",
    "*  희소 표현이 고차원에 각 차원이 분리된 표현 방법이었다면, 분산 표현은 저차원에 단어의 의미를 여러 차원에다가 분산하여 표현\r\n",
    "* NNLM, RNNLM 등이 있으나 요즘에는 해당 방법들의 속도를 대폭 개선시킨 Word2Vec가 많이 쓰이고 있다"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [Word2Vec = CBOW / Skip-Gram]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CBOW(Continuous Bag of Words)\r\n",
    "* 주변에 있는 단어들을 가지고, 중간에 있는 단어들을 예측하는 방법  \r\n",
    "  \r\n",
    "    \r\n",
    "예문 : \"The fat cat sat on the mat\"  \r\n",
    "->  {\"The\", \"fat\", \"cat\", \"on\", \"the\", \"mat\"}으로부터 sat을 예측  \r\n",
    "  \r\n",
    "  \r\n",
    "이 때 예측해야하는 단어 sat을 중심 단어(center word)라고 하고, 예측에 사용되는 단어들을 주변 단어(context word)라고 합니다. 중심 단어를 예측하기 위해서 앞, 뒤로 몇 개의 단어를 볼지를 결정했다면 이 범위를 윈도우(window)라고 합니다. 예를 들어서 윈도우 크기가 2이고, 예측하고자 하는 중심 단어가 sat이라고 한다면 앞의 두 단어인 fat와 cat, 그리고 뒤의 두 단어인 on, the를 참고합니다. 윈도우 크기가 n이라고 한다면, 실제 중심 단어를 예측하기 위해 참고하려고 하는 주변 단어의 개수는 2n이 될 것입니다.  \r\n",
    "  \r\n",
    "    \r\n",
    "   <img src=\"https://wikidocs.net/images/page/22660/%EB%8B%A8%EC%96%B4.PNG\" width=\"400\" height=\"400\">    \r\n",
    "     \r\n",
    "윈도우 크기를 정했다면, 윈도우를 계속 움직여서 주변 단어와 중심 단어 선택을 바꿔가며 학습을 위한 데이터 셋을 만들 수 있는데, 이 방법을 슬라이딩 윈도우(sliding window)라고 합니다"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "a64de8b745ab094eb3381810b1d090f0053b4977cc21c07d5a367fb401258f96"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}