{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1.torch\r\n",
    "tensor등의 다양한 수학 함수가 포함되어 있으며 numpy와 유사한 구조를 가진다. \r\n",
    "\r\n",
    "## 2.torch.autograd\r\n",
    "자동 미분을 위한 함수들이 포함되어 있다. \r\n",
    "\r\n",
    "## 3.torch.nn\r\n",
    "신경망을 구축하기 위한 다양한 데이터 구조나 레이어 등이 정의되어져 있다. \r\n",
    "\r\n",
    "## 4.torch.optim\r\n",
    "SGD를 중심으로 한 파라미터 최적화 알고리즘의 구현되어 있다.\r\n",
    "\r\n",
    "## 5.torch.utils.data\r\n",
    "SGD의 반복 연산을 실행할 때 사용하는 미니 배치용 유틸리티 함수가 포함되어 있다. \r\n",
    "\r\n",
    "## 6.torch.onnx\r\n",
    "ONNX(Open Neural Network Exchange)의 포맷으로 모델을 익스포트(export)할 때 사용한다. ONNX는 서로 다른 딥 러닝 프레임워크 간에 모델을 공유할 때 사용하는 포맷이다.\r\n",
    "\r\n",
    "---\r\n",
    "# 텐서 조작하기 1\r\n",
    "  ## 벡터, 행렬, 텐서\r\n",
    "    *스칼라 : 차원이 없는 값\r\n",
    "    *벡터 : 1차원으로 구성된 값\r\n",
    "    *행렬 : 2차원으로 구성된 값\r\n",
    "    *텐서 : 3차원 이상\r\n",
    "  ### 자연어 처리는 보통(batch size, 문장 길이, 단어 벡터의 차원)이라는 3차원 텐서를 사용한다.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 넘파이로 텐서 만들기(벡터와 행렬 만들기)\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# 1D \r\n",
    "t = np.array([0,1,2,3,4,5,6])\r\n",
    "print(t)\r\n",
    "print(t.ndim)\r\n",
    "print(t.shape)\r\n",
    "print(t[0],t[1],t[-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "1\n",
      "(7,)\n",
      "0 1 6\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 2D\r\n",
    "t = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\r\n",
    "print(t)\r\n",
    "print(t.ndim)\r\n",
    "print(t.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "2\n",
      "(4, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import torch\r\n",
    "\r\n",
    "# 1D\r\n",
    "t = torch.FloatTensor([0,1,2,3,4,5,6])\r\n",
    "print(t)\r\n",
    "print(t.dim()) # 차원\r\n",
    "print(t.size()) # shape\r\n",
    "print(t.shape) # shape \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n",
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 2D\r\n",
    "t = torch.FloatTensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\r\n",
    "print(t)\r\n",
    "print(t.dim())\r\n",
    "print(t.size())\r\n",
    "print(t[:,1])  # 첫번째 차원을 전체 선택한 상황에서 두번째 차원의 첫번째 것만 가져온다.\r\n",
    "print(t[:, :-1]) # 첫번째 차원을 전체 선택한 상황에서 두번째 차원에서는 맨 마지막에서 첫번째를 제외하고 다 가져온다."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 브로드캐스팅(broadcasting)\r\n",
    "\r\n",
    "# 두 행렬이 곱셈을 할 때는 a의 마지막 차원과 b의 첫번째 차원이 일치해야한다.\r\n",
    "# 파이토치에서는 자동으로 크기를 맞춰서 연산을 수행하게 하는 브로드캐스팅 기능을 제공한다.\r\n",
    "\r\n",
    "m1 = torch.FloatTensor([[3,3]]) \r\n",
    "m2 = torch.FloatTensor([[2,2]])\r\n",
    "\r\n",
    "print(m1+m2)\r\n",
    "\r\n",
    "# vector + scalar\r\n",
    "m3 = torch.FloatTensor([[1,2]]) \r\n",
    "m4 = torch.FloatTensor([3])\r\n",
    "\r\n",
    "print(m3+m4)\r\n",
    "\r\n",
    "# 2 x 1 vector + 1 x 2 vector\r\n",
    "m5 = torch.FloatTensor([[1,2]]) \r\n",
    "m6 = torch.FloatTensor([[3],[4]])\r\n",
    "\r\n",
    "print(m5+m6)\r\n",
    "\r\n",
    "\r\n",
    "# 브로드캐스팅은 자동으로 수행되므로 사용자는 나중에 원하는 결과가 나오지 않았더라도 \r\n",
    "# 어디서 문제가 발생했는지 찾기가 굉장히 어려울 수 있다."
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ff1741b10635>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 파이토치에서는 자동으로 크기를 맞춰서 연산을 수행하게 하는 브로드캐스팅 기능을 제공한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 1) 행렬 곱셈과 곱셈의 차이(Matrix Multiplication Vs. Multiplication)\r\n",
    "\r\n",
    "# 행렬 곱셈\r\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\r\n",
    "m2 = torch.FloatTensor([[1], [2]])\r\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\r\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\r\n",
    "print(m1.matmul(m2))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-072ab3df782d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 행렬 곱셈\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Shape of Matrix 1: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 2 x 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('chch': conda)"
  },
  "interpreter": {
   "hash": "a64de8b745ab094eb3381810b1d090f0053b4977cc21c07d5a367fb401258f96"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}